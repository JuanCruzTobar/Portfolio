{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a8e2a72b",
      "metadata": {
        "id": "a8e2a72b"
      },
      "outputs": [],
      "source": [
        "# Librerias\n",
        "# Tratamiento de datos\n",
        "# ==============================================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pandas.core.frame import DataFrame\n",
        "# Gráficos\n",
        "# ==============================================================================\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# Preprocesado y modelado\n",
        "# ==============================================================================\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "from statsmodels.stats.weightstats import ttest_ind\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, median_absolute_error\n",
        "from pandas.api.types import is_numeric_dtype\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "sns.set_context(\"talk\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "86d097c7",
      "metadata": {
        "id": "86d097c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "ffde36f4-1cd6-47e4-ced9-583953b531f2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'C:/Users/54351/Downloads/Base 5 Incumplimiento de préstamo(2).csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-826863a9ec97>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"C:/Users/54351/Downloads/Base 5 Incumplimiento de préstamo(2).csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/54351/Downloads/Base 5 Incumplimiento de préstamo(2).csv'"
          ]
        }
      ],
      "source": [
        "df=pd.read_csv(\"C:/Users/54351/Downloads/Base 5 Incumplimiento de préstamo(2).csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a916cf40",
      "metadata": {
        "id": "a916cf40"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49ec9253",
      "metadata": {
        "id": "49ec9253"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75016742",
      "metadata": {
        "id": "75016742"
      },
      "outputs": [],
      "source": [
        "# Eliminamos columnas innecesarias\n",
        "cols_to_drop = ['Unnamed: 0', 'year']\n",
        "df = df.drop(columns=cols_to_drop)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "758acacd",
      "metadata": {
        "id": "758acacd"
      },
      "outputs": [],
      "source": [
        "## Separo para posteriormente hacer el dummy\n",
        "\n",
        "categorical=[\n",
        "    \"Gender\",\"approv_in_adv\",\"loan_type\",\"loan_purpose\",\"loan_purpose\"\n",
        "    ,\"Credit_Worthiness\",\"open_credit\",\"business_or_commercial\",\"Neg_ammortization\"\n",
        "    ,\"interest_only\",\"lump_sum_payment\",\"construction_type\",\"occupancy_type\",\"Secured_by\"\n",
        "    ,\"total_units\",\"credit_type\",\"co-applicant_credit_type\",\"age\",\"submission_of_application\"\n",
        "    ,\"Region\",\"Security_Type\",\"loan_limit\"\n",
        "]\n",
        "numeric =[\n",
        "    \"loan_amount\",\"term\",\"income\",\"Credit_Score\",\"Upfront_charges\",\"LTV\",\"property_value\"\n",
        "    ,\"dtir1\",\"Status\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99613a13",
      "metadata": {
        "id": "99613a13"
      },
      "outputs": [],
      "source": [
        " # Impugnamos valores nulos en las variables categóricas, reemplazándolos\n",
        "    # por la moda\n",
        "for col in categorical:\n",
        "    df[col] = df[col].fillna(df[col].mode().values[0])\n",
        "    # Impugnamos valores nulos en las variables numéricas, reemplazándolos\n",
        "    # por la mediana\n",
        "for col in numeric:\n",
        "    df[col] = df[col].fillna(df[col].median())\n",
        "\n",
        "\n",
        "    # Verificamos que no existan valores nulos en el dataset final\n",
        "assert df.isna().any().any() == False\n",
        "\n",
        "    # Verificamos que todas las columnas numéricas son variables numéricas\n",
        "assert np.all(is_numeric_dtype(df[col]) for col in df.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15993b8e",
      "metadata": {
        "id": "15993b8e"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff29cc9d",
      "metadata": {
        "id": "ff29cc9d"
      },
      "outputs": [],
      "source": [
        "encoded_categorias=pd.get_dummies(df[categorical])\n",
        "df=pd.concat([encoded_categorias,df[numeric]], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b90b145d",
      "metadata": {
        "id": "b90b145d"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "828b8e8e",
      "metadata": {
        "id": "828b8e8e"
      },
      "outputs": [],
      "source": [
        "X=df.drop([\"Status\"],axis = 1) #variables clasificadoras (features)\n",
        "y=df.Status # grupo (target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89d8a8fc",
      "metadata": {
        "id": "89d8a8fc"
      },
      "outputs": [],
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=42, stratify=y)\n",
        "pd.value_counts(df['Status'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2225088d",
      "metadata": {
        "id": "2225088d"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import fbeta_score, accuracy_score, f1_score, precision_score, recall_score  # métricas para evaluar\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "!pip install lightgbm\n",
        "from lightgbm import LGBMClassifier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e36b280c",
      "metadata": {
        "id": "e36b280c"
      },
      "outputs": [],
      "source": [
        "## tarda demasasiadoooooo no volver a correr\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "# en este caso proponemos una búsqueda de la mejor estimación del modelo logístico armando una grilla dbe parámetros\n",
        "# definimos en solver distintos métodos de estimación posibles de la logística que permite la función LogisticRegression  del paquete sklearn.linear\n",
        "solver = ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']\n",
        "# y en C se definen parámetros de regularización que aceleran el proceso de estimación (a medida que son más grandes) en este caso se proponen un vector de valores\n",
        "# aleatorios espaciados según una escala logarítmica ( podrían haberse seleccionado en forma uniforme que son los nros aleatorios que se conocen comunmente).\n",
        "C = np.logspace(-2, 10, 13)\n",
        "# definimos el modelo a estimar LogisticRegression previo estandarizar los datos con StandardScaler\n",
        "pipe_LGBM = Pipeline([('sc', StandardScaler()),\n",
        "    ('LGBM', LGBMClassifier())\n",
        "    ])\n",
        "# definimos los vactores de parámetros para hacer las estimaciones\n",
        "params_lr= {\n",
        "    'LGBM__n_estimators': [5, 7, 10, 12, 15],\n",
        "    'LGBM__max_depth': [5, 7, 10, 12, 15, 20],\n",
        "    'LGBM__learning_rate': [0.01, 0.1, 0.25, 0.5, 0.75, 1],\n",
        "    'LGBM__random_state': [11]\n",
        "    }\n",
        "# proponemos la busqueda del mejor modelo según el resultado de la mejor clasificación (accuracy) con la tasa crosvalidada (GridSearchCV)\n",
        "search_lr = GridSearchCV(estimator=pipe_LGBM,\n",
        "                      param_grid=params_lr,\n",
        "                      cv = 5,\n",
        "                      scoring=\"roc_auc\",\n",
        "                      return_train_score=True)\n",
        "\n",
        "search_lr.fit(X_train, y_train)\n",
        "print(f\" Best score is: {search_lr.best_score_} with parameters: {search_lr.best_params_}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5a23f53",
      "metadata": {
        "id": "b5a23f53"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f77854b4",
      "metadata": {
        "id": "f77854b4"
      },
      "outputs": [],
      "source": [
        "##hiperparametros optimizados pero no se usan ya que la mejora no es significativa\n",
        "#params = {\n",
        "#    'learning_rate': 0.25,\n",
        "#    'max_depth': 20,\n",
        "#    'n_estimators': 15,\n",
        "#    'random_state': 11,\n",
        "#}\n",
        "\n",
        "pipe_LGBM = Pipeline([('sc', StandardScaler()),\n",
        "    ('LGBM', LGBMClassifier())])\n",
        "pipe_LGBM.fit(X_train,y_train)\n",
        "y_pred_lr = pipe_LGBM.predict(X_test)\n",
        "y_pred_train = pipe_LGBM.predict(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c54aab48",
      "metadata": {
        "id": "c54aab48"
      },
      "outputs": [],
      "source": [
        "pip install tabulate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01072d7a",
      "metadata": {
        "id": "01072d7a"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import fbeta_score, accuracy_score, f1_score, precision_score, recall_score  # métricas para evaluar\n",
        "from tabulate import tabulate\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "print('--------------------')\n",
        "print('Tabla de confusión en train')\n",
        "print('-------------------')\n",
        "CM_train = confusion_matrix(y_train,y_pred_train)  # Matriz de confusión en train\n",
        "print(CM_train)\n",
        "print('--------------------')\n",
        "print('Reporte de medidas de desempeño en train')\n",
        "print('-------------------')\n",
        "print(classification_report(y_train,y_pred_train, digits = 2))\n",
        "print('accuracy: ', accuracy_score(y_train,y_pred_train))\n",
        "classification_rep2 = classification_report(y_train,y_pred_train, digits=2, output_dict=True)\n",
        "print('--------------------')\n",
        "print('Tabla de confusión en test')\n",
        "print('-------------------')\n",
        "CM = confusion_matrix(y_test,y_pred_lr)  # Matriz de confusión en test\n",
        "print(CM)\n",
        "print('--------------------')\n",
        "print('Reporte de medidas de desempeño')\n",
        "print('-------------------')\n",
        "print(classification_report(y_test,y_pred_lr, digits = 2))\n",
        "print('accuracy: ', accuracy_score(y_test,y_pred_lr))\n",
        "classification_rep1 = classification_report(y_test, y_pred_lr, digits=2, output_dict=True)\n",
        "\n",
        "print('-------------------')\n",
        "print('Resumen de medidas en train ')\n",
        "print('-------------------')\n",
        "# Convierte el informe en una tabla con tabulate\n",
        "\n",
        "print('-------------------')\n",
        "print('Resumen de medidas en test')\n",
        "print('-------------------')\n",
        "table = [[\"Clase\", \"Precisión\", \"Recuperación\", \"F1-Score\", \"Soporte\"]]\n",
        "for label, scores in classification_rep1.items():\n",
        "    if label.isnumeric():\n",
        "        table.append([label, scores['precision'], scores['recall'], scores['f1-score'], scores['support']])\n",
        "# Muestra la tabla con colores y formato\n",
        "print(tabulate(table, headers=\"firstrow\", tablefmt=\"fancy_grid\", numalign=\"center\", stralign=\"center\"))\n",
        "\n",
        "\n",
        "# Imprime la exactitud\n",
        "print('Exactitud:', accuracy_score(y_test, y_pred_lr))\n",
        "\n",
        "\n",
        "\n",
        "# Convierte el informe en una tabla con tabulate\n",
        "table = [[\"Clase\", \"Precisión\", \"Recuperación\", \"F1-Score\", \"Soporte\"]]\n",
        "for label, scores in classification_rep2.items():\n",
        "    if label.isnumeric():\n",
        "        table.append([label, scores['precision'], scores['recall'], scores['f1-score'], scores['support']])\n",
        "\n",
        "# Muestra la tabla con colores y formato\n",
        "print(tabulate(table, headers=\"firstrow\", tablefmt=\"fancy_grid\", numalign=\"center\", stralign=\"center\"))\n",
        "\n",
        "# Imprime la exactitud\n",
        "print('Exactitud:', accuracy_score(y_train, y_pred_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f58fff51",
      "metadata": {
        "id": "f58fff51"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import RocCurveDisplay\n",
        "log_cor_est = RocCurveDisplay.from_estimator(pipe_LGBM,X_test, y_test,)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "350372e3",
      "metadata": {
        "id": "350372e3"
      },
      "outputs": [],
      "source": [
        "## no me toma el codigo\n",
        "\n",
        "features_trasformed=list(X.columns.values)\n",
        "fi=list(pipe_LGBM[\"LGBM\"].feature_importances_)\n",
        "\n",
        "feature_importance_df=pd.DataFrame()\n",
        "feature_importance_df[\"feature\"]=features_trasformed\n",
        "feature_importance_df[\"feature_importance\"]=fi\n",
        "feature_importance_df=feature_importance_df.sort_values(by=\"feature_importance\",ascending=False)\n",
        "feature_importance_df.head(20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7767ccb4",
      "metadata": {
        "id": "7767ccb4"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Crear una figura con subplots 2x3\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "\n",
        "# Lista de las columnas a graficar\n",
        "columnas = [\"Credit_Score\", \"LTV\", \"income\", \"dtir1\", \"loan_amount\"]\n",
        "\n",
        "# Lista de etiquetas de las columnas\n",
        "etiquetas = [\"Credit Score\", \"LTV\", \"Income\", \"DTIR1\", \"Loan Amount\"]\n",
        "\n",
        "# Recorrido para crear los boxplots\n",
        "for i, columna in enumerate(columnas):\n",
        "    row = i // 3\n",
        "    col = i % 3\n",
        "    sns.boxplot(data=df, x=\"Status\", y=columna, ax=axes[row, col], showfliers=False)\n",
        "    axes[row, col].set_title(f\"{etiquetas[i]} vs. Status\")\n",
        "\n",
        "# Ajustar los espacios entre los subplots\n",
        "plt.tight_layout()\n",
        "\n",
        "# Mostrar la figura con los boxplots en una matriz 2x3\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b27dae2",
      "metadata": {
        "id": "7b27dae2"
      },
      "outputs": [],
      "source": [
        "## Ahora realizamos un analisis de las variables clasificatorias\n",
        "## importamos la base limpia sin realizar el dummy para hacer el analisis con variables clasificatoria\n",
        "df1=pd.read_csv(\"C:/Users/54351/Downloads/Base 5 Incumplimiento de préstamo.csv\")\n",
        "\n",
        "cols_to_drop = ['Unnamed: 0', 'year']\n",
        "df1 = df1.drop(columns=cols_to_drop)\n",
        "\n",
        "categorical=[\n",
        "    \"Gender\",\"approv_in_adv\",\"loan_type\",\"loan_purpose\",\"loan_purpose\"\n",
        "    ,\"Credit_Worthiness\",\"open_credit\",\"business_or_commercial\",\"Neg_ammortization\"\n",
        "    ,\"interest_only\",\"lump_sum_payment\",\"construction_type\",\"occupancy_type\",\"Secured_by\"\n",
        "    ,\"total_units\",\"credit_type\",\"co-applicant_credit_type\",\"age\",\"submission_of_application\"\n",
        "    ,\"Region\",\"Security_Type\",\"loan_limit\"\n",
        "]\n",
        "numeric =[\n",
        "    \"loan_amount\",\"term\",\"income\",\"Credit_Score\",\"Upfront_charges\",\"LTV\",\"property_value\"\n",
        "    ,\"dtir1\",\"Status\"\n",
        "]\n",
        " # Impugnamos valores nulos en las variables categóricas, reemplazándolos\n",
        "    # por la moda\n",
        "for col in categorical:\n",
        "    df1[col] = df1[col].fillna(df1[col].mode().values[0])\n",
        "    # Impugnamos valores nulos en las variables numéricas, reemplazándolos\n",
        "    # por la mediana\n",
        "for col in numeric:\n",
        "    df1[col] = df1[col].fillna(df1[col].median())\n",
        "\n",
        "\n",
        "    # Verificamos que no existan valores nulos en el dataset final\n",
        "assert df1.isna().any().any() == False\n",
        "\n",
        "    # Verificamos que todas las columnas numéricas son variables numéricas\n",
        "assert np.all(is_numeric_dtype(df[col]) for col in df1.columns)\n",
        "df1.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f955320",
      "metadata": {
        "id": "1f955320"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Crear una figura con subplots 3x3\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "\n",
        "# Lista de columnas a graficar\n",
        "columnas = [\"credit_type\", \"Credit_Worthiness\", \"Neg_ammortization\", \"occupancy_type\", \"loan_purpose\"]\n",
        "\n",
        "# Recorrido para crear los gráficos en la misma fila\n",
        "for i, columna in enumerate(columnas):\n",
        "    row = i // 3\n",
        "    col = i % 3\n",
        "    sns.histplot(df1, x=columna, hue=\"Status\", stat=\"probability\", multiple=\"fill\", ax=axes[row, col])\n",
        "    axes[row, col].set_title(f'{columna} vs. Status')\n",
        "\n",
        "# Ajustar los espacios entre los subplots\n",
        "plt.tight_layout()\n",
        "\n",
        "# Mostrar la figura con los gráficos en una matriz 3x3\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a82427c5",
      "metadata": {
        "id": "a82427c5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}